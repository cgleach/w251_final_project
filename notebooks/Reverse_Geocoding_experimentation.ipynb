{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Notebook To Experiment with Geo Location\n\nKey items explored:\n    1) Can we import .shp files from US Govt for use in extracting zip codes\n    2) Can we use pyshp and Shapely to load .shp files and correctly identify the zip code based on polygon", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 47, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting pyshp\nInstalling collected packages: pyshp\nSuccessfully installed pyshp-2.0.1\nCollecting Shapely\n  Using cached https://files.pythonhosted.org/packages/81/d1/b8e1b089a8ddd6df74be583d70373eac55c725c6197c115efbd3c3e1509f/Shapely-1.6.4.post2-cp27-cp27mu-manylinux1_x86_64.whl\nInstalling collected packages: Shapely\nSuccessfully installed Shapely-1.6.4.post2\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "pillow 4.0.0 requires olefile, which is not installed.\ntensorflow 1.7.0 has requirement numpy>=1.13.3, but you'll have numpy 1.11.3 which is incompatible.\npyrax 1.9.8 has requirement python-novaclient==2.27.0, but you'll have python-novaclient 10.2.0 which is incompatible.\ntensorboard 1.7.0 has requirement futures>=3.1.1; python_version < \"3\", but you'll have futures 3.0.5 which is incompatible.\ntensorboard 1.7.0 has requirement numpy>=1.12.0, but you'll have numpy 1.11.3 which is incompatible.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/shapefile.py already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/shapefile.pyc already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/pyshp-2.0.1.dist-info already exists. Specify --upgrade to force replacement.\npillow 4.0.0 requires olefile, which is not installed.\ntensorflow 1.7.0 has requirement numpy>=1.13.3, but you'll have numpy 1.11.3 which is incompatible.\npyrax 1.9.8 has requirement python-novaclient==2.27.0, but you'll have python-novaclient 10.2.0 which is incompatible.\ntensorboard 1.7.0 has requirement futures>=3.1.1; python_version < \"3\", but you'll have futures 3.0.5 which is incompatible.\ntensorboard 1.7.0 has requirement numpy>=1.12.0, but you'll have numpy 1.11.3 which is incompatible.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/shapely already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/Shapely-1.6.4.post2.dist-info already exists. Specify --upgrade to force replacement.\n"
                }
            ], 
            "source": "%%sh\npip install pyshp\npip install Shapely"
        }, 
        {
            "execution_count": 39, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import shapefile\nfrom shapely.geometry import Point # Point class\nfrom shapely.geometry import shape # shape() is a function to convert geo objects through the interface\nfrom shapely.geometry import geo"
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df = spark.read.csv('/data/al/*', header=True).persist()"
        }, 
        {
            "execution_count": 4, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Read in shapefile from location in HDFS\nshp = shapefile.Reader('/home/wce/clsadmin/data/shapes/cb_2017_us_zcta510_500k.shp') "
        }, 
        {
            "source": "# Manual testing of idea", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 10, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "('The point is in', u'04978')\n"
                }
            ], 
            "source": "point = (-69.8007998,44.6594852) # an x,y tuple\n\nall_shapes = shp.shapes() # get all the polygons\nall_records = shp.records()\nfor i in range(0,len(all_shapes)):\n    boundary = all_shapes[i] # get a boundary polygon\n    if Point(point).within(shape(boundary)): # make a point and see if it's in the polygon\n        name = all_records[i][2] # get the second field of the corresponding record\n        print (\"The point is in\", name )"
        }, 
        {
            "source": "# Scaling ", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Create a udf which takes in a long/lat and loops through all the .shp files until correct one is found, and returns zip code\ndef my_udf(row):\n    import shapefile\n    from shapely.geometry import Point # Point class\n    from shapely.geometry import shape # shape() is a function to convert geo objects through the interface\n    from shapely.geometry import geo\n    import shapely.geometry\n    shp = shapefile.Reader('/home/wce/clsadmin/data/shapes/cb_2017_us_zcta510_500k.shp') #open the shapefile\n    all_shapes = shp.shapes() # get all the polygons\n    all_records = shp.records()\n    if row.POSTCODE is None:\n        for i in range(0,len(all_shapes)):\n            boundary = all_shapes[i] # get a boundary polygon\n            if Point(point).within(shape(boundary)): # make a point and see if it's in the polygon\n                name = all_records[i][2] # get the second field of the corresponding record\n                return name\n        return None\n    else:\n        return row.POSTCODE\n\nudf_calc_zip = udf(my_udf, StringType())"
        }, 
        {
            "execution_count": 165, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "df.withColumn('infer_zip', udf_calc_zip(struct(['LON','LAT','POSTCODE']))).filter(df.POSTCODE.isNull()).show()"
        }, 
        {
            "source": "# Errors with Above\n\nUnfortunately we were unable to get the above working at scale as we received errors related to our packages.  After research we believe this stems from Shapely and pyshp not being available on our compute nodes (we installed on master node).  Despite our best efforts, we could not ascertain a way to install these packages throughout the cluster.  We opted instead of use an \"infer_zip\" methodology based on nearest distance to the central long/lat of each zip code.", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.5 with Spark 2.3 (YARN Client Mode)", 
            "name": "python3-spark23", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "3.5.2", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython3", 
            "codemirror_mode": {
                "version": 3, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}