{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# Notebook 1\n\nIn this notebook we accomplish the following items:\n    * Ensure we are truly connected to cluster, and can download packages as required\n    * Infer \"State\" when missing based on initial location of file and save to HDFS\n    * Count number of missing data items for each row and write to HDFS (Necessary as time consuming)", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/home/wce/clsadmin\n"
                }
            ], 
            "source": "%%sh \n# Can see we're in right spot\npwd"
        }, 
        {
            "source": "## Installing Packages we might need", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting python-dotenv\n  Using cached https://files.pythonhosted.org/packages/8c/14/501508b016e7b1ad0eb91bba581e66ad9bfc7c66fcacbb580eaf9bc38458/python_dotenv-0.10.1-py2.py3-none-any.whl\nInstalling collected packages: python-dotenv\nSuccessfully installed python-dotenv-0.10.1\nCollecting plotly\n  Using cached https://files.pythonhosted.org/packages/32/d6/82333db5a6f56f828d817d49ae6ea153125d70214a189686afe784e159ad/plotly-3.4.2-py2.py3-none-any.whl\nCollecting requests (from plotly)\n  Using cached https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl\nCollecting nbformat>=4.2 (from plotly)\n  Using cached https://files.pythonhosted.org/packages/da/27/9a654d2b6cc1eaa517d1c5a4405166c7f6d72f04f6e7eea41855fe808a46/nbformat-4.4.0-py2.py3-none-any.whl\nCollecting pytz (from plotly)\n  Using cached https://files.pythonhosted.org/packages/f8/0e/2365ddc010afb3d79147f1dd544e5ee24bf4ece58ab99b16fbb465ce6dc0/pytz-2018.7-py2.py3-none-any.whl\nCollecting six (from plotly)\n  Using cached https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\nCollecting decorator>=4.0.6 (from plotly)\n  Using cached https://files.pythonhosted.org/packages/bc/bb/a24838832ba35baf52f32ab1a49b906b5f82fb7c76b2f6a7e35e140bac30/decorator-4.3.0-py2.py3-none-any.whl\nCollecting retrying>=1.3.3 (from plotly)\nCollecting urllib3<1.25,>=1.21.1 (from requests->plotly)\n  Using cached https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl\nCollecting certifi>=2017.4.17 (from requests->plotly)\n  Using cached https://files.pythonhosted.org/packages/9f/e0/accfc1b56b57e9750eba272e24c4dddeac86852c2bebd1236674d7887e8a/certifi-2018.11.29-py2.py3-none-any.whl\nCollecting idna<2.9,>=2.5 (from requests->plotly)\n  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\nCollecting chardet<3.1.0,>=3.0.2 (from requests->plotly)\n  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\nCollecting traitlets>=4.1 (from nbformat>=4.2->plotly)\n  Using cached https://files.pythonhosted.org/packages/93/d6/abcb22de61d78e2fc3959c964628a5771e47e7cc60d53e9342e21ed6cc9a/traitlets-4.3.2-py2.py3-none-any.whl\nCollecting jsonschema!=2.5.0,>=2.4 (from nbformat>=4.2->plotly)\n  Using cached https://files.pythonhosted.org/packages/77/de/47e35a97b2b05c2fadbec67d44cfcdcd09b8086951b331d82de90d2912da/jsonschema-2.6.0-py2.py3-none-any.whl\nCollecting jupyter-core (from nbformat>=4.2->plotly)\n  Using cached https://files.pythonhosted.org/packages/1d/44/065d2d7bae7bebc06f1dd70d23c36da8c50c0f08b4236716743d706762a8/jupyter_core-4.4.0-py2.py3-none-any.whl\nCollecting ipython-genutils (from nbformat>=4.2->plotly)\n  Using cached https://files.pythonhosted.org/packages/fa/bc/9bd3b5c2b4774d5f33b2d544f1460be9df7df2fe42f352135381c347c69a/ipython_genutils-0.2.0-py2.py3-none-any.whl\nCollecting enum34; python_version == \"2.7\" (from traitlets>=4.1->nbformat>=4.2->plotly)\n  Using cached https://files.pythonhosted.org/packages/c5/db/e56e6b4bbac7c4a06de1c50de6fe1ef3810018ae11732a50f15f62c7d050/enum34-1.1.6-py2-none-any.whl\nCollecting functools32; python_version == \"2.7\" (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2->plotly)\nInstalling collected packages: urllib3, certifi, idna, chardet, requests, six, enum34, decorator, ipython-genutils, traitlets, functools32, jsonschema, jupyter-core, nbformat, pytz, retrying, plotly\nSuccessfully installed certifi-2018.11.29 chardet-3.0.4 decorator-4.3.0 enum34-1.1.6 functools32-3.2.3.post2 idna-2.8 ipython-genutils-0.2.0 jsonschema-2.6.0 jupyter-core-4.4.0 nbformat-4.4.0 plotly-3.4.2 pytz-2018.7 requests-2.21.0 retrying-1.3.3 six-1.12.0 traitlets-4.3.2 urllib3-1.24.1\nCollecting pyshp\nInstalling collected packages: pyshp\nSuccessfully installed pyshp-2.0.1\nCollecting Shapely\n  Using cached https://files.pythonhosted.org/packages/81/d1/b8e1b089a8ddd6df74be583d70373eac55c725c6197c115efbd3c3e1509f/Shapely-1.6.4.post2-cp27-cp27mu-manylinux1_x86_64.whl\nInstalling collected packages: Shapely\nSuccessfully installed Shapely-1.6.4.post2\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "pillow 4.0.0 requires olefile, which is not installed.\ntensorflow 1.7.0 has requirement numpy>=1.13.3, but you'll have numpy 1.11.3 which is incompatible.\npyrax 1.9.8 has requirement python-novaclient==2.27.0, but you'll have python-novaclient 10.2.0 which is incompatible.\ntensorboard 1.7.0 has requirement futures>=3.1.1; python_version < \"3\", but you'll have futures 3.0.5 which is incompatible.\ntensorboard 1.7.0 has requirement numpy>=1.12.0, but you'll have numpy 1.11.3 which is incompatible.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/dotenv already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/python_dotenv-0.10.1.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/bin already exists. Specify --upgrade to force replacement.\npillow 4.0.0 requires olefile, which is not installed.\ntensorflow 1.7.0 has requirement numpy>=1.13.3, but you'll have numpy 1.11.3 which is incompatible.\npyrax 1.9.8 has requirement python-novaclient==2.27.0, but you'll have python-novaclient 10.2.0 which is incompatible.\ntensorboard 1.7.0 has requirement futures>=3.1.1; python_version < \"3\", but you'll have futures 3.0.5 which is incompatible.\ntensorboard 1.7.0 has requirement numpy>=1.12.0, but you'll have numpy 1.11.3 which is incompatible.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/urllib3 already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/urllib3-1.24.1.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/certifi already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/certifi-2018.11.29.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/idna already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/idna-2.8.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/chardet already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/chardet-3.0.4.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/requests already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/requests-2.21.0.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/six.py already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/six.pyc already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/six-1.12.0.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/enum already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/enum34-1.1.6.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/decorator.py already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/decorator.pyc already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/decorator-4.3.0.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/ipython_genutils already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/ipython_genutils-0.2.0.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/traitlets already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/traitlets-4.3.2.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/functools32 already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/functools32-3.2.3.post2.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/jsonschema already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/jsonschema-2.6.0.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/jupyter.py already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/jupyter.pyc already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/jupyter_core already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/jupyter_core-4.4.0.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/nbformat already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/nbformat-4.4.0.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/pytz already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/pytz-2018.7.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/retrying.py already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/retrying.pyc already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/retrying-1.3.3.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/_plotly_utils already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/plotly already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/plotlywidget already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/plotly-3.4.2.dist-info already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/bin already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/etc already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/share already exists. Specify --upgrade to force replacement.\npillow 4.0.0 requires olefile, which is not installed.\ntensorflow 1.7.0 has requirement numpy>=1.13.3, but you'll have numpy 1.11.3 which is incompatible.\npyrax 1.9.8 has requirement python-novaclient==2.27.0, but you'll have python-novaclient 10.2.0 which is incompatible.\ntensorboard 1.7.0 has requirement futures>=3.1.1; python_version < \"3\", but you'll have futures 3.0.5 which is incompatible.\ntensorboard 1.7.0 has requirement numpy>=1.12.0, but you'll have numpy 1.11.3 which is incompatible.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/shapefile.py already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/shapefile.pyc already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/pyshp-2.0.1.dist-info already exists. Specify --upgrade to force replacement.\npillow 4.0.0 requires olefile, which is not installed.\ntensorflow 1.7.0 has requirement numpy>=1.13.3, but you'll have numpy 1.11.3 which is incompatible.\npyrax 1.9.8 has requirement python-novaclient==2.27.0, but you'll have python-novaclient 10.2.0 which is incompatible.\ntensorboard 1.7.0 has requirement futures>=3.1.1; python_version < \"3\", but you'll have futures 3.0.5 which is incompatible.\ntensorboard 1.7.0 has requirement numpy>=1.12.0, but you'll have numpy 1.11.3 which is incompatible.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/shapely already exists. Specify --upgrade to force replacement.\nTarget directory /home/wce/clsadmin/pipAnaconda2Packages/Shapely-1.6.4.post2.dist-info already exists. Specify --upgrade to force replacement.\n"
                }
            ], 
            "source": "%%sh\npip install python-dotenv\npip install plotly\npip install pyshp\npip install Shapely"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Packages needed for notebook\nimport plotly\nimport pandas\nimport dotenv\n\nimport math\nfrom pyspark.sql.functions import udf, struct\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import lit\nfrom functools import reduce  # For Python 3.x\nfrom pyspark.sql import DataFrame\n\nimport shapefile\nfrom shapely.geometry import Point # Point class\nfrom shapely.geometry import shape # shape() is a function to convert geo objects through the interface\n\n# Function to concat dataframes\ndef unionAll(*dfs):\n    return reduce(DataFrame.unionAll, dfs)\n\n"
        }, 
        {
            "execution_count": 18, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# define state list\nstatesCap = [\"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DC\", \"DE\", \n             \"FL\", \"GA\", \"HI\", \"ID\", \"IL\", \"IN\", \"IA\", \"KS\", \"KY\", \n             \"LA\", \"ME\", \"MD\", \"MA\", \"MI\", \"MN\", \"MS\", \"MO\", \"MT\", \n             \"NE\", \"NV\", \"NH\", \"NJ\", \"NM\", \"NY\", \"NC\", \"ND\", \"OH\", \n             \"OK\", \"OR\", \"PA\", \"RI\", \"SC\", \"SD\", \"TN\", \"TX\", \"UT\", \n             \"VT\", \"VA\", \"WA\", \"WV\", \"WI\", \"WY\"]\nstates = [x.lower() for x in statesCap]"
        }, 
        {
            "execution_count": 5, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [], 
            "source": "# def add_state_and_dedupe(states):\n#     \"\"\"\n#     Adds known state to each set of files, dedupes, and unions into a single df\n#     \"\"\"\n#     first_state = True\n#     for state in states:\n#         pathway = \"/data/%s/*\" %state\n#         print(pathway)\n#         df = spark.read.csv(pathway, header=True).persist()\n#         df = df.withColumn('State',lit(state))\n#         df = df.drop_duplicates().persist()\n#         df = df.drop('REGION').persist()\n#         if first_state:\n#             full_df = df\n#             first_state=False\n#         else:\n#             full_df = unionAll(full_df, df).persist()\n#     # Our full dataset size (takes some time) \n#     full_df = full_df.drop_duplicates().persist()  \n#     return full_df\n\n\n# full_df = add_state_and_dedupe(states)"
        }, 
        {
            "execution_count": 6, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/data/al/*\n/data/ak/*\n/data/az/*\n/data/ar/*\n/data/ca/*\n/data/co/*\n/data/ct/*\n/data/dc/*\n/data/de/*\n/data/fl/*\n/data/ga/*\n/data/hi/*\n/data/id/*\n/data/il/*\n/data/in/*\n/data/ia/*\n/data/ks/*\n/data/ky/*\n/data/la/*\n/data/me/*\n/data/md/*\n/data/ma/*\n/data/mi/*\n/data/mn/*\n/data/ms/*\n/data/mo/*\n/data/mt/*\n/data/ne/*\n/data/nv/*\n/data/nh/*\n/data/nj/*\n/data/nm/*\n/data/ny/*\n/data/nc/*\n/data/nd/*\n/data/oh/*\n/data/ok/*\n/data/or/*\n/data/pa/*\n/data/ri/*\n/data/sc/*\n/data/sd/*\n/data/tn/*\n/data/tx/*\n/data/ut/*\n/data/vt/*\n/data/va/*\n/data/wa/*\n/data/wv/*\n/data/wi/*\n/data/wy/*\n"
                }, 
                {
                    "execution_count": 6, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "'Write Complete'"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "def add_state_and_dedupe(states):\n    \"\"\"\n    Adds known state to each set of files, dedupes, and unions into a single df\n    \"\"\"\n    first_state = True\n    for state in states:\n        pathway = \"/data/%s/*\" %state\n        print(pathway)\n        df = spark.read.csv(pathway, header=True).persist()\n        df = df.withColumn('State',lit(state))\n        df = df.drop_duplicates().persist()\n        df = df.drop('REGION').persist()\n        output_path = '/clean_states/%s' %state\n        df.write.csv(output_path, header=True)\n    return \"Write Complete\"\n\n\nadd_state_and_dedupe(states)"
        }, 
        {
            "execution_count": 23, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "/clean_states/al/*\n/clean_states/ak/*\n/clean_states/az/*\n/clean_states/ar/*\n/clean_states/ca/*\n/clean_states/co/*\n/clean_states/ct/*\n/clean_states/dc/*\n/clean_states/de/*\n/clean_states/fl/*\n/clean_states/ga/*\n/clean_states/hi/*\n/clean_states/id/*\n/clean_states/il/*\n/clean_states/in/*\n/clean_states/ia/*\n/clean_states/ks/*\n/clean_states/ky/*\n/clean_states/la/*\n/clean_states/me/*\n/clean_states/md/*\n/clean_states/ma/*\n/clean_states/mi/*\n/clean_states/mn/*\n/clean_states/ms/*\n/clean_states/mo/*\n/clean_states/mt/*\n/clean_states/ne/*\n/clean_states/nv/*\n/clean_states/nh/*\n/clean_states/nj/*\n/clean_states/nm/*\n/clean_states/ny/*\n/clean_states/nc/*\n/clean_states/nd/*\n/clean_states/oh/*\n/clean_states/ok/*\n/clean_states/or/*\n/clean_states/pa/*\n/clean_states/ri/*\n/clean_states/sc/*\n/clean_states/sd/*\n/clean_states/tn/*\n/clean_states/tx/*\n/clean_states/ut/*\n/clean_states/vt/*\n/clean_states/va/*\n/clean_states/wa/*\n/clean_states/wv/*\n/clean_states/wi/*\n/clean_states/wy/*\n"
                }, 
                {
                    "execution_count": 23, 
                    "metadata": {}, 
                    "data": {
                        "text/plain": "'Write Complete'"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "from pyspark.sql.functions import udf, struct\nfrom pyspark.sql.types import IntegerType\n\ndef count_missing(states):\n    \"\"\"\n    Adds known state to each set of files, dedupes, and unions into a single df\n    \"\"\"\n    for state in states:\n        pathway = \"/clean_states/%s/*\" %state\n        print(pathway)\n        df = spark.read.csv(pathway, header=True).persist()\n        count_empty_columns = udf(lambda row: len([x for x in row if x == None]), IntegerType())\n        new_df = df.withColumn(\"null_count\", count_empty_columns(struct([df[x] for x in df.columns])))\n        output_path = '/states_missingness/%s' %state\n        new_df.write.csv(output_path, header=True)\n    return \"Write Complete\"\n\n\ncount_missing(states)"
        }, 
        {
            "source": "Supplemental data cleaning was done directly through scripts as processes were too compute intense\n\n# End Notebook", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2.7 with Spark 2.3 (YARN Client Mode)", 
            "name": "python2-spark23", 
            "language": "python"
        }, 
        "language_info": {
            "mimetype": "text/x-python", 
            "nbconvert_exporter": "python", 
            "version": "2.7.13", 
            "name": "python", 
            "file_extension": ".py", 
            "pygments_lexer": "ipython2", 
            "codemirror_mode": {
                "version": 2, 
                "name": "ipython"
            }
        }
    }, 
    "nbformat": 4
}