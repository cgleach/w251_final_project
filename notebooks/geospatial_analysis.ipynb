{
    "nbformat_minor": 1, 
    "cells": [
        {
            "source": "# GeoSpatial Graphing\n\n        *Primary purpose of this notebook is to create visualizations for our address data before\n        combining that data with tax return data and producing additional graphics.  We primarily\n        employ plotly for visuals, and pyspark for analytics", 
            "cell_type": "markdown", 
            "metadata": {}
        }, 
        {
            "execution_count": 2, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Collecting plotly\n  Downloading https://files.pythonhosted.org/packages/32/d6/82333db5a6f56f828d817d49ae6ea153125d70214a189686afe784e159ad/plotly-3.4.2-py2.py3-none-any.whl (37.8MB)\nCollecting requests (from plotly)\n  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\nCollecting nbformat>=4.2 (from plotly)\n  Downloading https://files.pythonhosted.org/packages/da/27/9a654d2b6cc1eaa517d1c5a4405166c7f6d72f04f6e7eea41855fe808a46/nbformat-4.4.0-py2.py3-none-any.whl (155kB)\nCollecting pytz (from plotly)\n  Downloading https://files.pythonhosted.org/packages/f8/0e/2365ddc010afb3d79147f1dd544e5ee24bf4ece58ab99b16fbb465ce6dc0/pytz-2018.7-py2.py3-none-any.whl (506kB)\nCollecting six (from plotly)\n  Downloading https://files.pythonhosted.org/packages/73/fb/00a976f728d0d1fecfe898238ce23f502a721c0ac0ecfedb80e0d88c64e9/six-1.12.0-py2.py3-none-any.whl\nCollecting decorator>=4.0.6 (from plotly)\n  Downloading https://files.pythonhosted.org/packages/bc/bb/a24838832ba35baf52f32ab1a49b906b5f82fb7c76b2f6a7e35e140bac30/decorator-4.3.0-py2.py3-none-any.whl\nCollecting retrying>=1.3.3 (from plotly)\n  Downloading https://files.pythonhosted.org/packages/44/ef/beae4b4ef80902f22e3af073397f079c96969c69b2c7d52a57ea9ae61c9d/retrying-1.3.3.tar.gz\nCollecting urllib3<1.25,>=1.21.1 (from requests->plotly)\n  Downloading https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl (118kB)\nCollecting certifi>=2017.4.17 (from requests->plotly)\n  Downloading https://files.pythonhosted.org/packages/9f/e0/accfc1b56b57e9750eba272e24c4dddeac86852c2bebd1236674d7887e8a/certifi-2018.11.29-py2.py3-none-any.whl (154kB)\nCollecting idna<2.9,>=2.5 (from requests->plotly)\n  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\nCollecting chardet<3.1.0,>=3.0.2 (from requests->plotly)\n  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\nCollecting traitlets>=4.1 (from nbformat>=4.2->plotly)\n  Downloading https://files.pythonhosted.org/packages/93/d6/abcb22de61d78e2fc3959c964628a5771e47e7cc60d53e9342e21ed6cc9a/traitlets-4.3.2-py2.py3-none-any.whl (74kB)\nCollecting jsonschema!=2.5.0,>=2.4 (from nbformat>=4.2->plotly)\n  Downloading https://files.pythonhosted.org/packages/77/de/47e35a97b2b05c2fadbec67d44cfcdcd09b8086951b331d82de90d2912da/jsonschema-2.6.0-py2.py3-none-any.whl\nCollecting jupyter-core (from nbformat>=4.2->plotly)\n  Downloading https://files.pythonhosted.org/packages/1d/44/065d2d7bae7bebc06f1dd70d23c36da8c50c0f08b4236716743d706762a8/jupyter_core-4.4.0-py2.py3-none-any.whl (126kB)\nCollecting ipython-genutils (from nbformat>=4.2->plotly)\n  Downloading https://files.pythonhosted.org/packages/fa/bc/9bd3b5c2b4774d5f33b2d544f1460be9df7df2fe42f352135381c347c69a/ipython_genutils-0.2.0-py2.py3-none-any.whl\nCollecting enum34; python_version == \"2.7\" (from traitlets>=4.1->nbformat>=4.2->plotly)\n  Downloading https://files.pythonhosted.org/packages/c5/db/e56e6b4bbac7c4a06de1c50de6fe1ef3810018ae11732a50f15f62c7d050/enum34-1.1.6-py2-none-any.whl\nCollecting functools32; python_version == \"2.7\" (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2->plotly)\n  Downloading https://files.pythonhosted.org/packages/c5/60/6ac26ad05857c601308d8fb9e87fa36d0ebf889423f47c3502ef034365db/functools32-3.2.3-2.tar.gz\nBuilding wheels for collected packages: retrying, functools32\n  Running setup.py bdist_wheel for retrying: started\n  Running setup.py bdist_wheel for retrying: finished with status 'done'\n  Stored in directory: /home/wce/clsadmin/.cache/pip/wheels/d7/a9/33/acc7b709e2a35caa7d4cae442f6fe6fbf2c43f80823d46460c\n  Running setup.py bdist_wheel for functools32: started\n  Running setup.py bdist_wheel for functools32: finished with status 'done'\n  Stored in directory: /home/wce/clsadmin/.cache/pip/wheels/b5/18/32/77a1030457155606ba5e3ec3a8a57132b1a04b1c4f765177b2\nSuccessfully built retrying functools32\nInstalling collected packages: urllib3, certifi, idna, chardet, requests, six, enum34, decorator, ipython-genutils, traitlets, functools32, jsonschema, jupyter-core, nbformat, pytz, retrying, plotly\nSuccessfully installed certifi-2018.11.29 chardet-3.0.4 decorator-4.3.0 enum34-1.1.6 functools32-3.2.3.post2 idna-2.8 ipython-genutils-0.2.0 jsonschema-2.6.0 jupyter-core-4.4.0 nbformat-4.4.0 plotly-3.4.2 pytz-2018.7 requests-2.21.0 retrying-1.3.3 six-1.12.0 traitlets-4.3.2 urllib3-1.24.1\n"
                }, 
                {
                    "output_type": "stream", 
                    "name": "stderr", 
                    "text": "pillow 4.0.0 requires olefile, which is not installed.\ntensorflow 1.7.0 has requirement numpy>=1.13.3, but you'll have numpy 1.11.3 which is incompatible.\npyrax 1.9.8 has requirement python-novaclient==2.27.0, but you'll have python-novaclient 10.2.0 which is incompatible.\ntensorboard 1.7.0 has requirement futures>=3.1.1; python_version < \"3\", but you'll have futures 3.0.5 which is incompatible.\ntensorboard 1.7.0 has requirement numpy>=1.12.0, but you'll have numpy 1.11.3 which is incompatible.\n"
                }
            ], 
            "source": "%%sh\npip install plotly\npip install geopandas==0.3.0\npip install pyshp==1.2.10\npip install shapely==1.6.3"
        }, 
        {
            "execution_count": 1, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "Waiting for a Spark session to start...\nSpark Initialization Done! ApplicationId = application_1545094219751_0004\n"
                }
            ], 
            "source": "# Packages needed for notebook\nimport plotly.plotly as py\nimport plotly.figure_factory as ff\nplotly.tools.set_credentials_file(username='cgleach',api_key='ssuPH1Q9MyqSd2tMcNzz')\n\nimport pandas\nimport shapefile\nimport shapely\nimport geopandas\n"
        }, 
        {
            "execution_count": 79, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Read in previously generated summary data for plotting\ndf = spark.read.csv('/final_state_housing_counts',header=True)\ndf = df.filter(df.State.isNotNull())\nstate_housing_counts = df.toPandas()\nstate_housing_counts['State'] = state_housing_counts['State'].apply(lambda x: x.upper())\nstate_housing_counts['num_addresses'] = (state_housing_counts['num_addresses'].astype(float)/1000000)"
        }, 
        {
            "execution_count": 81, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 81, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cgleach/34.embed\" height=\"525px\" width=\"100%\"></iframe>", 
                        "text/plain": "<plotly.tools.PlotlyDisplay object>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "# Create interactive visualization using plotly\nimport plotly.plotly as py\nimport pandas as pd\n\n\nscl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\\\n           [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n\ndata = [ dict(\n        type='choropleth',\n        colorscale = scl,\n        autocolorscale = False,\n        locations = state_housing_counts['State'],\n        z = state_housing_counts['num_addresses'],\n        locationmode = 'USA-states',\n        text = '',\n        marker = dict(\n            line = dict (\n                color = 'rgb(255,255,255)',\n                width = 2\n            ) ),\n        colorbar = dict(\n            title = \"Millions of Addresses\")\n        ) ]\n\nlayout = dict(\n        title = '#Addressses by State',\n        geo = dict(\n            scope='usa',\n            projection=dict( type='albers usa' ),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)'),\n             )\n    \nfig = dict( data=data, layout=layout )\npy.iplot( fig, filename='d3-cloropleth-map' )"
        }, 
        {
            "execution_count": 167, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 167, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fips</th>\n      <th>num_addresses</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>55085</td>\n      <td>38.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>45061</td>\n      <td>18.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>30061</td>\n      <td>4.9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>48227</td>\n      <td>20.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>48359</td>\n      <td>0.1</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "    fips  num_addresses\n0  55085           38.1\n1  45061           18.6\n2  30061            4.9\n3  48227           20.2\n4  48359            0.1"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "df = spark.read.csv('/final_fips_housing_counts', header=True)\ndf = df.filter(df.fips.isNotNull())\nfips_housing_counts = df.toPandas()\nfips_housing_counts['fips'] = fips_housing_counts['fips'].astype(str)\nfips_housing_counts['num_addresses'] = (fips_housing_counts['num_addresses'].astype(float)/1000).round(1)\nfips_housing_counts = fips_housing_counts[fips_housing_counts['fips'] != '35013'] #Doesn't seem to be real\nfips_housing_counts.head()"
        }, 
        {
            "execution_count": 169, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "The draw time for this plot will be slow for clients without much RAM.\n"
                }, 
                {
                    "execution_count": 169, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cgleach/36.embed\" height=\"450px\" width=\"900px\"></iframe>", 
                        "text/plain": "<plotly.tools.PlotlyDisplay object>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import plotly.plotly as py\nimport plotly.figure_factory as ff\n\nfips = fips_housing_counts['fips']\nvalues = fips_housing_counts['num_addresses']\n\nfig = ff.create_choropleth(fips=fips, values=values, legend_title='Addresses (1000s)', \n                           title='#Addresses By County',binning_endpoints=[1, 2, 5, 10, 15, 25, 35, 50, 100, 250, 500],)\npy.iplot(fig, filename='choropleth of county address numbers')"
        }, 
        {
            "execution_count": 177, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 177, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fips</th>\n      <th>fips_null_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>27131</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>30061</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>45061</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>16055</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16069</td>\n      <td>4.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>", 
                        "text/plain": "    fips  fips_null_count\n0  27131              3.0\n1  30061              5.0\n2  45061              3.0\n3  16055              4.0\n4  16069              4.0"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "df = spark.read.csv('/final_fips_missing_counts', header=True)\ndf = df.filter(df.fips.isNotNull())\nfips_missing_counts = df.toPandas()\nfips_missing_counts.head()\nfips_missing_counts['fips'] = fips_missing_counts['fips'].astype(str)\nfips_missing_counts['fips_null_count'] = fips_missing_counts['fips_null_count'].astype(float).round(0)\nfips_missing_counts = fips_missing_counts[fips_missing_counts['fips'] != '35013'] #Doesn't seem to be real\nfips_missing_counts.head()"
        }, 
        {
            "execution_count": 180, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "output_type": "stream", 
                    "name": "stdout", 
                    "text": "The draw time for this plot will be slow for clients without much RAM.\n"
                }, 
                {
                    "execution_count": 180, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cgleach/38.embed\" height=\"450px\" width=\"900px\"></iframe>", 
                        "text/plain": "<plotly.tools.PlotlyDisplay object>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import plotly.plotly as py\nimport plotly.figure_factory as ff\n\nfips = fips_missing_counts['fips']\nvalues = fips_missing_counts['fips_null_count']\n\nfig = ff.create_choropleth(fips=fips, values=values, legend_title='Avg. Missing Data', \n                           title='Missing Data by County')\npy.iplot(fig, filename='choropleth of county missing data numbers')"
        }, 
        {
            "execution_count": 184, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "df = spark.read.csv('/final_state_missing_counts',header=True)\ndf = df.filter(df.State.isNotNull())\nstate_missing_counts = df.toPandas()\nstate_missing_counts.head()\nstate_missing_counts['State'] = state_missing_counts['State'].apply(lambda x: x.upper())\nstate_missing_counts['state_null_count'] = state_missing_counts['state_null_count'].astype(float).round(0)\n"
        }, 
        {
            "execution_count": 195, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": false
            }, 
            "outputs": [
                {
                    "execution_count": 195, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cgleach/34.embed\" height=\"525px\" width=\"100%\"></iframe>", 
                        "text/plain": "<plotly.tools.PlotlyDisplay object>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import plotly.plotly as py\nimport pandas as pd\n\n\n#scl = [[0.0, 'rgb(242,240,247)'],[0.2, 'rgb(218,218,235)'],[0.4, 'rgb(188,189,220)'],\\\n#           [0.6, 'rgb(158,154,200)'],[0.8, 'rgb(117,107,177)'],[1.0, 'rgb(84,39,143)']]\n\ndata = [ dict(\n        type='choropleth',\n        # The different colorscale options are a lot of fun\n        colorscale = 'Rainbow',\n        autocolorscale = False,\n        locations = state_missing_counts['State'],\n        z = state_missing_counts['state_null_count'],\n        locationmode = 'USA-states',\n        #text ='',\n        marker = dict(\n            line = dict (\n                color = 'rgb(255,255,255)',\n                width = 2\n            ) ),\n        colorbar = dict(\n            title = \"Missing Data Points\")\n        ) ]\n\nlayout = dict(\n        title = 'Avg. Missing Columns by State',\n        geo = dict(\n            scope='usa',\n            projection=dict( type='albers usa' ),\n            showlakes = True,\n            lakecolor = 'rgb(255, 255, 255)'),\n             )\n    \nfig = dict( data=data, layout=layout )\npy.iplot( fig, filename='d3-cloropleth-map' )"
        }, 
        {
            "execution_count": 38, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "import pandas as pd\nfrom pyspark.sql.functions import udf, struct\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import lit\nfrom functools import reduce  # For Python 3.x\nfrom pyspark.sql import DataFrame\nfrom pyspark.sql import SparkSession\nfrom pyspark.sql.types import *"
        }, 
        {
            "execution_count": 39, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def add_zeroes(value):\n    if len(value)==5:\n        return value\n    elif len(value)==4:\n        new_value = '0'+str(value)\n        return new_value\n    elif len(value)==3:\n        new_value = '00'+str(value)\n        return new_value\n    else:\n        return None\n    \nudf_add_zeroes = udf(add_zeroes, StringType())"
        }, 
        {
            "execution_count": 40, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def filing_address_ratio(row):\n    return row.num_returns/row.num_addresses\n    \nudf_ratio = udf(filing_address_ratio, IntegerType())"
        }, 
        {
            "execution_count": 63, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "from pyspark.sql.functions import sum\n\ndf = spark.read.csv('/final_data/ca/*',header=True)\ndf = df.withColumn(\"infer_zip\",udf_add_zeroes(df.infer_zip))\ndf = df.groupBy([\"infer_zip\",\"fips\"]).agg({\"LON\":\"count\"})\ntax = spark.read.csv('/data/tax_return_clean.csv', header=True)\ntax = tax.withColumn(\"num_returns\", tax.num_returns.cast(\"int\")).persist()\ntax = tax.withColumn(\"adj_gross_income\", tax.adj_gross_income.cast(\"int\")).persist()\n\n\ntax = tax.withColumn(\"student_loan_interest_deduction\", tax.student_loan_interest_deduction.cast(\"int\")).persist()\ntax = tax.withColumn(\"chartiable_contribution_amount\", tax.chartiable_contribution_amount.cast(\"int\")).persist()\ntax = tax.withColumn(\"returns_with_unemployment\", tax.returns_with_unemployment.cast(\"int\")).persist()\n\ntax = tax.groupBy([\"zipcode\"]).agg(sum(\"adj_gross_income\").alias(\"adj_gross_income\"),sum(\"num_returns\").alias(\"num_returns\")\n                                  ,sum(\"student_loan_interest_deduction\").alias(\"student_loan_interest_deduction\"),\n                                  sum(\"chartiable_contribution_amount\").alias(\"chartiable_contribution_amount\"),\n                                  sum(\"returns_with_unemployment\").alias(\"returns_with_unemployment\"))\ntax = tax.drop_duplicates().persist()\ntax = tax.withColumn(\"zipcode\",udf_add_zeroes(tax.zipcode))\ncombined = df.join(tax, tax.zipcode==df.infer_zip, 'inner')\n\ncombined_grouped = combined.groupBy(\"fips\").agg(sum(\"count(LON)\").alias(\"num_addresses\"),sum(\"num_returns\").alias(\"num_returns\"))\ncombined_grouped = combined_grouped.withColumn(\"filing_return_address_ratio\",udf_ratio(struct(['num_addresses','num_returns']))).persist()\ncombined_grouped=combined_grouped.filter(combined_grouped.fips.isNotNull())\ncombined_grouped = combined_grouped.toPandas()\ncombined_grouped = combined_grouped[combined_grouped['fips'] != '35013'] #Doesn't seem to be real"
        }, 
        {
            "execution_count": 71, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "# Force CA fips only, despite fact that dataset has incorrect data\na = combined_grouped[combined_grouped['fips'].astype(int)<10000]"
        }, 
        {
            "execution_count": 72, 
            "cell_type": "code", 
            "metadata": {
                "scrolled": true
            }, 
            "outputs": [
                {
                    "execution_count": 72, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cgleach/40.embed\" height=\"450px\" width=\"900px\"></iframe>", 
                        "text/plain": "<plotly.tools.PlotlyDisplay object>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import plotly.plotly as py\nimport plotly.figure_factory as ff\n\nfips = a['fips']\nvalues = a['filing_return_address_ratio']\n\nfig = ff.create_choropleth(fips=fips, values=values, legend_title='Ratio Returns:Addresses', \n                           title='Returns:Address Ratio',binning_endpoints=[.5, .75, 1, 1.25, 1.5, 2, 3, 5],\n                          scope=['CA', 'AZ', 'Nevada', 'Oregon', ' Idaho'])\npy.iplot(fig, filename='choropleth of county return vs address')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }, 
        {
            "execution_count": 93, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "def student_loan_per_household(row):\n    return (row.student_loan_interest_deduction*1000)/row.num_addresses\n    \nudf_ratio = udf(student_loan_per_household, DoubleType())"
        }, 
        {
            "execution_count": 94, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": "combined_grouped = combined.groupBy(\"fips\").agg(sum(\"count(LON)\").alias(\"num_addresses\"),\n                                                sum(\"student_loan_interest_deduction\").alias(\"student_loan_interest_deduction\"))\ncombined_grouped = combined_grouped.withColumn(\"num_addresses\",combined_grouped.num_addresses.cast(\"double\"))\ncombined_grouped = combined_grouped.withColumn(\"student_loan_interest_deduction\",combined_grouped.student_loan_interest_deduction.cast(\"double\"))\ncombined_grouped = combined_grouped.withColumn(\"student_loan_interest_per_household\",udf_ratio(struct(['num_addresses','student_loan_interest_deduction']))).persist()\ncombined_grouped=combined_grouped.filter(combined_grouped.fips.isNotNull())\ncombined_grouped = combined_grouped.toPandas()\ncombined_grouped = combined_grouped[combined_grouped['fips'] != '35013'] #Doesn't seem to be real\na = combined_grouped[combined_grouped['fips'].astype(int)<10000]"
        }, 
        {
            "execution_count": 96, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [
                {
                    "execution_count": 96, 
                    "metadata": {}, 
                    "data": {
                        "text/html": "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cgleach/42.embed\" height=\"450px\" width=\"900px\"></iframe>", 
                        "text/plain": "<plotly.tools.PlotlyDisplay object>"
                    }, 
                    "output_type": "execute_result"
                }
            ], 
            "source": "import plotly.plotly as py\nimport plotly.figure_factory as ff\n\nfips = a['fips']\nvalues = a['student_loan_interest_per_household']\n\nfig = ff.create_choropleth(fips=fips, values=values, legend_title='Student Loans Interest:Addresse', \n                           title='Student Loan Interest:Address Ratio',binning_endpoints=[10,25,50,75,100,150,200,250 ],\n                          scope=['CA', 'AZ', 'Nevada', 'Oregon', ' Idaho'])\npy.iplot(fig, filename='choropleth of county student loan interst vs address')"
        }, 
        {
            "execution_count": null, 
            "cell_type": "code", 
            "metadata": {}, 
            "outputs": [], 
            "source": ""
        }
    ], 
    "metadata": {
        "kernelspec": {
            "display_name": "Python 2.7 with Spark 2.3 (YARN Client Mode)", 
            "name": "python2-spark23", 
            "language": "python"
        }
    }, 
    "nbformat": 4
}